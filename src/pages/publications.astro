---
// import { getCollection } from "astro:content";
import Layout from '../layouts/Layout.astro';
// import Card from '../components/Card.astro';
// const allProjects = await getCollection("projects");
const pageTitle = "Publications";
---
<Layout pageTitle={pageTitle}>
    <!--<div class="gif">-->
    <!--    <img width="300" height="259" alt="RaccoonLaptopGif" src="/laptop.webp"/>-->
    <!--</div>-->
    <!--<h2>Publications</h2>-->
    <!--<div class="grid grid-cols-1 md:grid-cols-2 lg:grid-cols-3 gap-4">-->
    <!--    <div class="bg-gray-100 p-4 rounded-lg ">-->
    <!--        <p class="font-medium">-->
    <!--        Seeing Intuitive Physics-->
    <!--        </p>-->
    <!--        <p class="italic text-sm mb-2">-->
    <!--        Author, A., & Coauthor, B. (Year)-->
    <!--        </p>-->
    <!--        <p class="text-gray-600">Journal Name, volume(issue), pages</p>-->
    <!--        <a href="" class="text-blue-600 hover:underline">DOI</a>-->
    <!--    </div>-->
    <!--    <div class="bg-gray-100 p-4 rounded-lg ">-->
    <!--        <p class="font-medium">-->
    <!--        Spontaneous Visual Routines-->
    <!--        </p>-->
    <!--        <p class="italic text-sm mb-2">-->
    <!--        Author, A., & Coauthor, B. (Year)-->
    <!--        </p>-->
    <!--        <p class="text-gray-600">Journal Name, volume(issue), pages</p>-->
    <!--        <a href="" class="text-blue-600 hover:underline">DOI</a>-->
    <!--    </div>-->
    <!--    <div class="bg-gray-100 p-4 rounded-lg ">-->
    <!--        <p class="font-medium">-->
    <!--        The Title of Your Publication-->
    <!--        </p>-->
    <!--        <p class="italic text-sm mb-2">-->
    <!--        Author, A., & Coauthor, B. (Year)-->
    <!--        </p>-->
    <!--        <p class="text-gray-600">Journal Name, volume(issue), pages</p>-->
    <!--        <a href="" class="text-blue-600 hover:underline">DOI</a>-->
    <!--    </div>-->
    <!--</div>-->
    <h2>Publications</h2>
    <br>
    <span class="badge badge--item">MANUSCRIPTS</span>
    <p class="p1">
    Wong, K. W., & Scholl, B. J. (<i>under review</i>). Spontaneous path tracing in task-irrelevant mazes: Spatial affordances trigger dynamic visual routines.
    </p>
        <details><summary>[Click to show abstract]</summary>
            <p>
            Given a maze (e.g. in a book of puzzles), you might solve it by drawing out paths with your pencil.  But even without a pencil, you might naturally find yourself mentally tracing along various paths.  This ‘mental path tracing’ may intuitively seem to depend on your (overt, conscious, voluntary) goal of wanting to get out of the maze, but might it also occur spontaneously  &mdash; as a result of simply seeing the maze, via a kind of dynamic ‘visual routine’?  Here, observers simply had to compare the visual properties of two probes presented in a maze.  The maze itself was entirely task-irrelevant, but we predicted that simply seeing the maze’s visual structure would ‘afford’ incidental mental path tracing (à la Gibson).  Across four experiments, observers were slower to compare probes that were further from each other along the paths, even when controlling for lower-level properties (such as the probes’ brute linear separation, ignoring the maze ‘walls’).  These results also generalized beyond mazes, to other unfamiliar displays with task-irrelevant circular obstacles.  This novel combination of two prominent themes from our field  &mdash;  affordances and visual routines  &mdash;  suggests that at least some visual routines may not require voluntary goals; instead, they may operate in an automatic (incidental, stimulus-driven) fashion, as a part of visual processing itself.
            </p>
        </details>
    <p class="p1">
        Bi, W., Shah, A. D., Wong, K. W., Scholl, B. J., & Yildirim, I. (<i>submitted</i>). Computational models reveal that intuitive physics underlies visual processing of soft objects.
    </p>
        <details><summary>[Click to show abstract]</summary>
            <p>
            Computational explorations of human cognition have been especially successful when applied to visual perception. Existing models have primarily focused on rigid objects, emphasizing shapepreserving invariance to changes in viewpoint, lighting, object size, and scene context. Yet many objects in our everyday environments, such as cloths, are soft. This poses both quantitatively greater and qualitatively different challenges for models of perception, due to soft objects’ dynamic and high-dimensional internal structure  &mdash;  as in the changing folds and wrinkles of a cloth waving in the wind. Soft object perception is also correspondingly rich, involving novel properties such as stiffness. Here we explore the ability of different kinds of computational models to capture human visual perception of the physical properties of texture-equated cloths (e.g., their degrees of stiffness) that are undergoing different naturalistic transformations (e.g., falling vs. waving in the wind). Across visual matching tasks, both the successes and failures of human performance are well explained by <i>Woven</i>  &mdash;  a novel model that incorporates physics-based simulations to infer probabilistic representations of cloths. In contrast, competing models that are calibrated to equal performance as Woven on objective measures  &mdash;  including Woven ablations and a deep neural network  &mdash;  fail to capture human performance. We also confirm a novel prediction of Woven in additional analysis of our data. We suggest that humanlike machine vision may also require representations that transcend image features, and involve intuitive physics.
            </p>
        </details>
    <p class="p1">
        Ongchoco, J. D. K., Wong, K. W., & Scholl, B. J. (<i>in prep</i>). The “unfinishedness” of dynamic events is
        spontaneously extracted in visual perception: A new ‘Visual Zeigarnik Effect’.
    </p>
        <details><summary>[Click to show abstract]</summary>
            <p>
            The events that occupy our thoughts in an especially persistent way are often those that are unfinished &mdash; half-written papers, unfolded laundry, and items not yet crossed off from to-do lists. And this factor has also been emphasized in work within higher-level cognition, as in the "Zeigarnik effect": when people carry out various tasks, but some are never finished due to extrinsic interruptions, memory tends to be better for those tasks that were unfinished. But just how foundational is this sort of "unfinishedness" in mental life? Might such unfinishedness be spontaneously extracted and prioritized even in lower-level visual processing? To explore this, we had observers watch animations in which a dot moved through a maze, starting at one disc (the 'startpoint') and moving toward another disc (the 'endpoint'). We tested the fidelity of visual memory by having probes (colored squares) appear briefly along the dot's path; after the dot finished moving, observers simply had to indicate where the probes had appeared. On 'Completed' trials, the motion ended when the dot reached the endpoint, but on 'Unfinished' trials, the motion ended shortly before the dot reached the endpoint. Although this manipulation was entirely task-irrelevant, it nevertheless had a powerful influence on visual memory: observers placed probes much closer to their correct locations on Unfinished trials. This same pattern held across several different experiments, even while carefully controlling for various lower-level properties of the displays (such as the speed and duration of the dot's motion). And the effect also generalized across different types of displays (e.g. also replicating when the moving dot left a visible trace). This new type of <i>Visual Zeigarnik Effect</i> suggests that the unfinishedness of events is not just a matter of higher-level thought and motivation, but can also be extracted as a part of visual perception itself.
            </p>
        </details>
    <p class="p1">
        Wong, K. W., Shah, A. D. & Scholl, B. J. (<i>in prep</i>). Unconscious intuitive physics: Prioritized breakthrough into visual awareness for physically unstable block towers.
    </p>
        <details><summary>[Click to show abstract]</summary>
            <p>
            A central goal of perception and cognition is to predict how events in our local environments are likely to unfold: what is about to happen? And of course some of the most reliable ways of answering this question involve considering the regularities of physics. Accordingly, a great deal of recent research throughout cognitive science has explored the nature of ‘intuitive physics’. The vast majority of this work, however, has involved higher-level reasoning, rather than seeing itself &mdash; as when people are asked to deliberate about how objects might move, in response to explicit questions (“Will it fall?”). Here, in contrast, we ask whether the apprehension of certain physical properties of scenes might also occur *unconsciously*, during simple passive viewing. Moreover, we ask whether certain physical regularities are not just processed, but also visually *prioritized* &mdash; as when a tower is about to fall. Observers viewed block towers &mdash; some stable, some unstable &mdash; defined in terms of whether they would collapse as a result of external physical forces (such as gravity) alone. We used continuous flash suppression (CFS) to render the towers initially invisible: observers viewed them monocularly through a mirror haploscope, while a dynamic Mondrian mask was presented to their other eye. We then measured how long towers took to break through this interocular suppression, as observers indicated when they became visually aware of anything other than the mask. The results were clear and striking: unstable towers broke into visual awareness faster than stable towers. And this held even while controlling for other visual properties &mdash; e.g. while contrasting pairs of stable vs. unstable towers sharing the same convex hull, and differing only in the horizontal placement of a single block. This work shows how physical instability is both detected and prioritized, not only during overt deliberation, but also in unconscious visual processing.
            </p>
        </details>

    <!--<br><br>-->
    <span class="badge badge--item">JOURNAL ARTICLES</span>
    <p class="p1">
        Ongchoco, J. D. K., Wong, K. W., & Scholl, B. J. (2024).
        What's next?: Time is subjectively dilated not only for 'oddball' events, but also for events immediately after oddballs.
        <b><i>Attention, Perception, & Psychophysics</i></b>, <i>86</i>(1), 16-21.
    <br><a class="footer__link" href="https://doi.org/10.3758/s13414-023-02800-7" target="_blank">[DOI]</a>

    <p class="p1">
        Wong, K. W., Bi, W., Soltani, A. A., Yildirim, I., & Scholl, B. J. (2023). Seeing soft materials draped over objects: A case study of intuitive physics in perception, attention, and memory. <b><i>Psychological Science</i></b>, <i>34</i>(1), 111-119.
        <br><a class="footer__link" href="https://doi.org/10.1177/09567976221109194" target="_blank">[DOI]</a> <a class="footer__link" href="/wong-etal-2023-cloth-soft-materials.pdf" target="_blank">[PDF]</a>
    </p>

    <p class="p1">
        Wong, K., Wadee, F., Ellenblum, G., & McCloskey, M. (2018).
        The devil's in the g-tails: Deficient letter-shape knowledge and awareness despite massive visual experience.
        <b><i>Journal of Experimental Psychology: Human Perception and Performance</i></b>, <i>44</i>(9), 1324-1335.
    <br><a class="footer__link" href="https://pubmed.ncbi.nlm.nih.gov/29608074/" target="_blank">[DOI]</a>
</p>
    <!--<h2>Conference Talks & Presentations</h2>-->
</Layout>

